	quick_test: 0
	mode: dev
	dataset: foa
	input: raw
	model: rese
	augmentation: 1
	acs: 1
	dataset_dir: ../Datasets/SELD2020/
	feat_label_dir: ../Datasets/SELD2020/feat_label/
	model_dir: trained_model/
	dcase_output: True
	dcase_dir: results/
	fs: 24000
	hop_len_s: 0.02
	label_hop_len_s: 0.1
	max_audio_len_s: 60
	nb_mel_bins: 64
	batch_size: 16
	nb_epochs: 50
	optimizer: adam
	lr: 0.001
	scheduler: plateau
	dropout_rate: 0.2
	mixup: 0
	lad_doa_thresh: 20
	label_sequence_length: 60
	data_in: (7, 300, 64)
	data_out: [(60, 14), (60, 42)]
	feature_sequence_length: 300
	patience: 50
	unique_classes: {'alarm': 0, 'baby': 1, 'crash': 2, 'dog': 3, 'engine': 4, 'female_scream': 5, 'female_speech': 6, 'fire': 7, 'footsteps': 8, 'knock': 9, 'male_scream': 10, 'male_speech': 11, 'phone': 12, 'piano': 13}
unique_name: 05040140_rese_foa_dev

Loading training dataset:
	start to get fetch raw audio data
	Data frames shape: [n_samples, channel, audio_samples]:(4000, 8, 144000)

	Label shape:(4000, 60, 42)

	start fetch ACS data
	ACS Label shape:(4000, 60, 42)

	ACS data shape:(4000, 8, 144000)

	Final Data frames shape: [n_samples, channel, audio_samples]:torch.Size([8000, 8, 144000])

	Final Label shape:torch.Size([8000, 60, 42])

	files number: 400, classes number:14
	number of frames per file: 0, mel bins length: 64, channels number: 4
	feat length per sequence: 300, label length per sequence: 60

Loading validation dataset:
	start to get fetch raw audio data
	Data frames shape: [n_samples, channel, audio_samples]:(1000, 8, 144000)

	Label shape:(1000, 60, 42)

	files number: 100, classes number:14
	number of frames per file: 0, mel bins length: 64, channels number: 4
	feat length per sequence: 300, label length per sequence: 60

Loading test dataset:
	start to get fetch raw audio data
	Data frames shape: [n_samples, channel, audio_samples]:(1000, 8, 144000)

	Label shape:(1000, 60, 42)

	files number: 100, classes number:14
	number of frames per file: 0, mel bins length: 64, channels number: 4
	feat length per sequence: 300, label length per sequence: 60

----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1           [-1, 128, 48000]           3,200
       BatchNorm1d-2           [-1, 128, 48000]             256
              ReLU-3           [-1, 128, 48000]               0
            Conv1d-4           [-1, 128, 48000]          49,280
       BatchNorm1d-5           [-1, 128, 48000]             256
              ReLU-6           [-1, 128, 48000]               0
 AdaptiveAvgPool1d-7               [-1, 128, 1]               0
            Conv1d-8                 [-1, 8, 1]           1,024
              ReLU-9                 [-1, 8, 1]               0
           Conv1d-10               [-1, 128, 1]           1,024
          Sigmoid-11               [-1, 128, 1]               0
             ReLU-12           [-1, 128, 48000]               0
        MaxPool1d-13           [-1, 128, 16000]               0
      Basic_Block-14           [-1, 128, 16000]               0
           Conv1d-15           [-1, 128, 16000]          49,280
      BatchNorm1d-16           [-1, 128, 16000]             256
             ReLU-17           [-1, 128, 16000]               0
AdaptiveAvgPool1d-18               [-1, 128, 1]               0
           Conv1d-19                 [-1, 8, 1]           1,024
             ReLU-20                 [-1, 8, 1]               0
           Conv1d-21               [-1, 128, 1]           1,024
          Sigmoid-22               [-1, 128, 1]               0
             ReLU-23           [-1, 128, 16000]               0
        MaxPool1d-24            [-1, 128, 5333]               0
      Basic_Block-25            [-1, 128, 5333]               0
           Conv1d-26            [-1, 256, 5333]          33,024
      BatchNorm1d-27            [-1, 256, 5333]             512
           Conv1d-28            [-1, 256, 5333]          98,560
      BatchNorm1d-29            [-1, 256, 5333]             512
             ReLU-30            [-1, 256, 5333]               0
AdaptiveAvgPool1d-31               [-1, 256, 1]               0
           Conv1d-32                [-1, 16, 1]           4,096
             ReLU-33                [-1, 16, 1]               0
           Conv1d-34               [-1, 256, 1]           4,096
          Sigmoid-35               [-1, 256, 1]               0
             ReLU-36            [-1, 256, 5333]               0
        MaxPool1d-37            [-1, 256, 1777]               0
      Basic_Block-38            [-1, 256, 1777]               0
           Conv1d-39            [-1, 256, 1777]         196,864
      BatchNorm1d-40            [-1, 256, 1777]             512
             ReLU-41            [-1, 256, 1777]               0
AdaptiveAvgPool1d-42               [-1, 256, 1]               0
           Conv1d-43                [-1, 16, 1]           4,096
             ReLU-44                [-1, 16, 1]               0
           Conv1d-45               [-1, 256, 1]           4,096
          Sigmoid-46               [-1, 256, 1]               0
             ReLU-47            [-1, 256, 1777]               0
        MaxPool1d-48             [-1, 256, 592]               0
      Basic_Block-49             [-1, 256, 592]               0
           Conv1d-50             [-1, 256, 592]         196,864
      BatchNorm1d-51             [-1, 256, 592]             512
             ReLU-52             [-1, 256, 592]               0
AdaptiveAvgPool1d-53               [-1, 256, 1]               0
           Conv1d-54                [-1, 16, 1]           4,096
             ReLU-55                [-1, 16, 1]               0
           Conv1d-56               [-1, 256, 1]           4,096
          Sigmoid-57               [-1, 256, 1]               0
             ReLU-58             [-1, 256, 592]               0
        MaxPool1d-59             [-1, 256, 197]               0
      Basic_Block-60             [-1, 256, 197]               0
           Conv1d-61             [-1, 128, 197]          32,896
      BatchNorm1d-62             [-1, 128, 197]             256
           Conv1d-63             [-1, 128, 197]          98,432
      BatchNorm1d-64             [-1, 128, 197]             256
             ReLU-65             [-1, 128, 197]               0
AdaptiveAvgPool1d-66               [-1, 128, 1]               0
           Conv1d-67                 [-1, 8, 1]           1,024
             ReLU-68                 [-1, 8, 1]               0
           Conv1d-69               [-1, 128, 1]           1,024
          Sigmoid-70               [-1, 128, 1]               0
             ReLU-71             [-1, 128, 197]               0
        MaxPool1d-72              [-1, 128, 65]               0
      Basic_Block-73              [-1, 128, 65]               0
AdaptiveAvgPool1d-74              [-1, 128, 60]               0
        LayerNorm-75              [-1, 60, 128]             256
           Linear-76              [-1, 60, 512]          66,048
            Swish-77              [-1, 60, 512]               0
          Dropout-78              [-1, 60, 512]               0
           Linear-79              [-1, 60, 128]          65,664
          Dropout-80              [-1, 60, 128]               0
      FeedForward-81              [-1, 60, 128]               0
          PreNorm-82              [-1, 60, 128]               0
            Scale-83              [-1, 60, 128]               0
        LayerNorm-84              [-1, 60, 128]             256
           Linear-85              [-1, 60, 512]          65,536
           Linear-86             [-1, 60, 1024]         131,072
        Embedding-87               [-1, 60, 64]          65,600
           Linear-88              [-1, 60, 128]          65,664
          Dropout-89              [-1, 60, 128]               0
        Attention-90              [-1, 60, 128]               0
          PreNorm-91              [-1, 60, 128]               0
        LayerNorm-92              [-1, 60, 128]             256
2021-05-04 01:44:38.804016: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
        Transpose-93              [-1, 128, 60]               0
           Conv1d-94              [-1, 512, 60]          66,048
              GLU-95              [-1, 256, 60]               0
           Conv1d-96              [-1, 256, 60]           8,192
  DepthWiseConv1d-97              [-1, 256, 60]               0
      BatchNorm1d-98              [-1, 256, 60]             512
            Swish-99              [-1, 256, 60]               0
          Conv1d-100              [-1, 128, 60]          32,896
       Transpose-101              [-1, 60, 128]               0
         Dropout-102              [-1, 60, 128]               0
ConformerConvModule-103              [-1, 60, 128]               0
       LayerNorm-104              [-1, 60, 128]             256
          Linear-105              [-1, 60, 512]          66,048
           Swish-106              [-1, 60, 512]               0
         Dropout-107              [-1, 60, 512]               0
          Linear-108              [-1, 60, 128]          65,664
         Dropout-109              [-1, 60, 128]               0
     FeedForward-110              [-1, 60, 128]               0
         PreNorm-111              [-1, 60, 128]               0
           Scale-112              [-1, 60, 128]               0
       LayerNorm-113              [-1, 60, 128]             256
  ConformerBlock-114              [-1, 60, 128]               0
       LayerNorm-115              [-1, 60, 128]             256
          Linear-116              [-1, 60, 512]          66,048
           Swish-117              [-1, 60, 512]               0
         Dropout-118              [-1, 60, 512]               0
          Linear-119              [-1, 60, 128]          65,664
         Dropout-120              [-1, 60, 128]               0
     FeedForward-121              [-1, 60, 128]               0
         PreNorm-122              [-1, 60, 128]               0
           Scale-123              [-1, 60, 128]               0
       LayerNorm-124              [-1, 60, 128]             256
          Linear-125              [-1, 60, 512]          65,536
          Linear-126             [-1, 60, 1024]         131,072
       Embedding-127               [-1, 60, 64]          65,600
          Linear-128              [-1, 60, 128]          65,664
         Dropout-129              [-1, 60, 128]               0
       Attention-130              [-1, 60, 128]               0
         PreNorm-131              [-1, 60, 128]               0
       LayerNorm-132              [-1, 60, 128]             256
       Transpose-133              [-1, 128, 60]               0
          Conv1d-134              [-1, 512, 60]          66,048
             GLU-135              [-1, 256, 60]               0
          Conv1d-136              [-1, 256, 60]           8,192
 DepthWiseConv1d-137              [-1, 256, 60]               0
     BatchNorm1d-138              [-1, 256, 60]             512
           Swish-139              [-1, 256, 60]               0
          Conv1d-140              [-1, 128, 60]          32,896
       Transpose-141              [-1, 60, 128]               0
         Dropout-142              [-1, 60, 128]               0
ConformerConvModule-143              [-1, 60, 128]               0
       LayerNorm-144              [-1, 60, 128]             256
          Linear-145              [-1, 60, 512]          66,048
           Swish-146              [-1, 60, 512]               0
         Dropout-147              [-1, 60, 512]               0
          Linear-148              [-1, 60, 128]          65,664
         Dropout-149              [-1, 60, 128]               0
     FeedForward-150              [-1, 60, 128]               0
         PreNorm-151              [-1, 60, 128]               0
           Scale-152              [-1, 60, 128]               0
       LayerNorm-153              [-1, 60, 128]             256
  ConformerBlock-154              [-1, 60, 128]               0
          Linear-155                  [-1, 128]          16,512
 TimeDistributed-156              [-1, 60, 128]               0
         Dropout-157              [-1, 60, 128]               0
          Linear-158                   [-1, 42]           5,418
 TimeDistributed-159               [-1, 60, 42]               0
            Tanh-160               [-1, 60, 42]               0
================================================================
Total params: 2,214,826
Trainable params: 2,214,826
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 4.39
Forward/backward pass size (MB): 533.69
Params size (MB): 8.45
Estimated Total Size (MB): 546.53
----------------------------------------------------------------
Epoch [1/50], train loss : 0.0246
Epoch [1/50], val loss : 0.0221
epoch_cnt: 0, time: 114.49s, tr_loss: 0.02, 
		 DCASE2020 SCORES: SED_Error: 1.00, SED_F: 0.4, DOA_Error: 37.0, DOA_recall:1.2, seld_score (early stopping score): 0.80, best_seld_score: 0.80, best_epoch : 0

Epoch [2/50], train loss : 0.0216
Epoch [2/50], val loss : 0.0211
epoch_cnt: 1, time: 119.95s, tr_loss: 0.02, 
		 DCASE2020 SCORES: SED_Error: 0.98, SED_F: 4.2, DOA_Error: 20.2, DOA_recall:7.6, seld_score (early stopping score): 0.74, best_seld_score: 0.74, best_epoch : 1

Epoch [3/50], train loss : 0.0202
Epoch [3/50], val loss : 0.0190
epoch_cnt: 2, time: 120.89s, tr_loss: 0.02, 
		 DCASE2020 SCORES: SED_Error: 0.96, SED_F: 6.5, DOA_Error: 25.9, DOA_recall:21.4, seld_score (early stopping score): 0.71, best_seld_score: 0.71, best_epoch : 2

Epoch [4/50], train loss : 0.0190
Epoch [4/50], val loss : 0.0187
epoch_cnt: 3, time: 121.39s, tr_loss: 0.02, 
		 DCASE2020 SCORES: SED_Error: 0.91, SED_F: 15.0, DOA_Error: 20.7, DOA_recall:27.3, seld_score (early stopping score): 0.65, best_seld_score: 0.65, best_epoch : 3

Epoch [5/50], train loss : 0.0182
Epoch [5/50], val loss : 0.0173
epoch_cnt: 4, time: 121.80s, tr_loss: 0.02, 
		 DCASE2020 SCORES: SED_Error: 0.87, SED_F: 21.3, DOA_Error: 21.8, DOA_recall:38.7, seld_score (early stopping score): 0.60, best_seld_score: 0.60, best_epoch : 4

Epoch [6/50], train loss : 0.0175
Epoch [6/50], val loss : 0.0179
epoch_cnt: 5, time: 121.50s, tr_loss: 0.02, 
		 DCASE2020 SCORES: SED_Error: 0.91, SED_F: 15.3, DOA_Error: 22.1, DOA_recall:29.4, seld_score (early stopping score): 0.65, best_seld_score: 0.60, best_epoch : 4

Epoch [7/50], train loss : 0.0167
Epoch [7/50], val loss : 0.0170
epoch_cnt: 6, time: 121.28s, tr_loss: 0.02, 
		 DCASE2020 SCORES: SED_Error: 0.87, SED_F: 19.5, DOA_Error: 23.5, DOA_recall:38.2, seld_score (early stopping score): 0.61, best_seld_score: 0.60, best_epoch : 4

Epoch [8/50], train loss : 0.0161
Epoch [8/50], val loss : 0.0164
epoch_cnt: 7, time: 121.89s, tr_loss: 0.02, 
		 DCASE2020 SCORES: SED_Error: 0.83, SED_F: 26.1, DOA_Error: 20.6, DOA_recall:45.0, seld_score (early stopping score): 0.56, best_seld_score: 0.56, best_epoch : 7

Epoch [9/50], train loss : 0.0154
Epoch [9/50], val loss : 0.0156
epoch_cnt: 8, time: 123.65s, tr_loss: 0.02, 
		 DCASE2020 SCORES: SED_Error: 0.82, SED_F: 27.0, DOA_Error: 21.6, DOA_recall:50.4, seld_score (early stopping score): 0.54, best_seld_score: 0.54, best_epoch : 8

Epoch [10/50], train loss : 0.0147
Epoch [10/50], val loss : 0.0163
epoch_cnt: 9, time: 121.34s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.82, SED_F: 25.3, DOA_Error: 23.3, DOA_recall:49.1, seld_score (early stopping score): 0.55, best_seld_score: 0.54, best_epoch : 8

Epoch [11/50], train loss : 0.0142
Epoch [11/50], val loss : 0.0156
epoch_cnt: 10, time: 121.75s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.81, SED_F: 25.9, DOA_Error: 25.7, DOA_recall:57.4, seld_score (early stopping score): 0.53, best_seld_score: 0.53, best_epoch : 10

Epoch [12/50], train loss : 0.0136
Epoch [12/50], val loss : 0.0149
epoch_cnt: 11, time: 121.59s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.75, SED_F: 33.2, DOA_Error: 22.0, DOA_recall:57.5, seld_score (early stopping score): 0.49, best_seld_score: 0.49, best_epoch : 11

Epoch [13/50], train loss : 0.0131
Epoch [13/50], val loss : 0.0154
epoch_cnt: 12, time: 121.77s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.79, SED_F: 29.1, DOA_Error: 24.2, DOA_recall:56.8, seld_score (early stopping score): 0.52, best_seld_score: 0.49, best_epoch : 11

Epoch [14/50], train loss : 0.0126
Epoch [14/50], val loss : 0.0143
epoch_cnt: 13, time: 122.05s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.74, SED_F: 33.1, DOA_Error: 23.4, DOA_recall:63.7, seld_score (early stopping score): 0.48, best_seld_score: 0.48, best_epoch : 13

Epoch [15/50], train loss : 0.0122
Epoch [15/50], val loss : 0.0141
epoch_cnt: 14, time: 122.13s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.71, SED_F: 37.1, DOA_Error: 21.0, DOA_recall:62.7, seld_score (early stopping score): 0.46, best_seld_score: 0.46, best_epoch : 14

Epoch [16/50], train loss : 0.0118
Epoch [16/50], val loss : 0.0141
epoch_cnt: 15, time: 122.43s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.75, SED_F: 32.7, DOA_Error: 22.2, DOA_recall:63.7, seld_score (early stopping score): 0.48, best_seld_score: 0.46, best_epoch : 14

Epoch [17/50], train loss : 0.0114
Epoch [17/50], val loss : 0.0133
epoch_cnt: 16, time: 122.05s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.68, SED_F: 40.1, DOA_Error: 20.7, DOA_recall:66.5, seld_score (early stopping score): 0.43, best_seld_score: 0.43, best_epoch : 16

Epoch [18/50], train loss : 0.0110
Epoch [18/50], val loss : 0.0142
epoch_cnt: 17, time: 122.31s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.71, SED_F: 37.5, DOA_Error: 21.4, DOA_recall:64.2, seld_score (early stopping score): 0.45, best_seld_score: 0.43, best_epoch : 16

Epoch [19/50], train loss : 0.0107
Epoch [19/50], val loss : 0.0139
epoch_cnt: 18, time: 122.42s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.71, SED_F: 35.5, DOA_Error: 22.5, DOA_recall:66.7, seld_score (early stopping score): 0.45, best_seld_score: 0.43, best_epoch : 16

Epoch [20/50], train loss : 0.0103
Epoch [20/50], val loss : 0.0134
Epoch    20: reducing learning rate of group 0 to 2.0000e-04.
epoch_cnt: 19, time: 122.22s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.71, SED_F: 37.1, DOA_Error: 22.2, DOA_recall:67.6, seld_score (early stopping score): 0.45, best_seld_score: 0.43, best_epoch : 16

Epoch [21/50], train loss : 0.0086
Epoch [21/50], val loss : 0.0122
epoch_cnt: 20, time: 122.22s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.63, SED_F: 45.5, DOA_Error: 19.4, DOA_recall:70.6, seld_score (early stopping score): 0.39, best_seld_score: 0.39, best_epoch : 20

Epoch [22/50], train loss : 0.0082
Epoch [22/50], val loss : 0.0120
epoch_cnt: 21, time: 122.61s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.62, SED_F: 46.2, DOA_Error: 19.8, DOA_recall:72.2, seld_score (early stopping score): 0.39, best_seld_score: 0.39, best_epoch : 21

Epoch [23/50], train loss : 0.0080
Epoch [23/50], val loss : 0.0119
epoch_cnt: 22, time: 122.63s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.61, SED_F: 46.3, DOA_Error: 19.7, DOA_recall:72.2, seld_score (early stopping score): 0.38, best_seld_score: 0.38, best_epoch : 22

Epoch [24/50], train loss : 0.0078
Epoch [24/50], val loss : 0.0124
epoch_cnt: 23, time: 122.14s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.63, SED_F: 45.1, DOA_Error: 19.8, DOA_recall:71.1, seld_score (early stopping score): 0.39, best_seld_score: 0.38, best_epoch : 22

Epoch [25/50], train loss : 0.0077
Epoch [25/50], val loss : 0.0123
epoch_cnt: 24, time: 121.60s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.62, SED_F: 45.6, DOA_Error: 19.7, DOA_recall:71.3, seld_score (early stopping score): 0.39, best_seld_score: 0.38, best_epoch : 22

Epoch [26/50], train loss : 0.0076
Epoch [26/50], val loss : 0.0121
Epoch    26: reducing learning rate of group 0 to 4.0000e-05.
epoch_cnt: 25, time: 121.34s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.61, SED_F: 46.7, DOA_Error: 19.5, DOA_recall:72.3, seld_score (early stopping score): 0.38, best_seld_score: 0.38, best_epoch : 25

Epoch [27/50], train loss : 0.0073
Epoch [27/50], val loss : 0.0121
epoch_cnt: 26, time: 121.49s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.61, SED_F: 46.8, DOA_Error: 19.4, DOA_recall:71.9, seld_score (early stopping score): 0.38, best_seld_score: 0.38, best_epoch : 26

Epoch [28/50], train loss : 0.0072
Epoch [28/50], val loss : 0.0122
epoch_cnt: 27, time: 121.52s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.61, SED_F: 46.4, DOA_Error: 19.6, DOA_recall:72.0, seld_score (early stopping score): 0.38, best_seld_score: 0.38, best_epoch : 26

Epoch [29/50], train loss : 0.0071
Epoch [29/50], val loss : 0.0122
Epoch    29: reducing learning rate of group 0 to 8.0000e-06.
epoch_cnt: 28, time: 121.08s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.62, SED_F: 46.6, DOA_Error: 19.5, DOA_recall:71.8, seld_score (early stopping score): 0.38, best_seld_score: 0.38, best_epoch : 26

Epoch [30/50], train loss : 0.0070
Epoch [30/50], val loss : 0.0121
epoch_cnt: 29, time: 120.90s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.62, SED_F: 46.1, DOA_Error: 19.6, DOA_recall:72.1, seld_score (early stopping score): 0.39, best_seld_score: 0.38, best_epoch : 26

Epoch [31/50], train loss : 0.0070
Epoch [31/50], val loss : 0.0122
epoch_cnt: 30, time: 124.38s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.62, SED_F: 46.6, DOA_Error: 19.5, DOA_recall:72.1, seld_score (early stopping score): 0.38, best_seld_score: 0.38, best_epoch : 26

Epoch [32/50], train loss : 0.0070
Epoch [32/50], val loss : 0.0122
Epoch    32: reducing learning rate of group 0 to 1.6000e-06.
epoch_cnt: 31, time: 119.52s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.62, SED_F: 46.0, DOA_Error: 19.5, DOA_recall:72.0, seld_score (early stopping score): 0.39, best_seld_score: 0.38, best_epoch : 26

Epoch [33/50], train loss : 0.0070
Epoch [33/50], val loss : 0.0121
epoch_cnt: 32, time: 120.70s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.61, SED_F: 46.6, DOA_Error: 19.5, DOA_recall:72.3, seld_score (early stopping score): 0.38, best_seld_score: 0.38, best_epoch : 32

Epoch [34/50], train loss : 0.0070
Epoch [34/50], val loss : 0.0122
epoch_cnt: 33, time: 123.18s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.62, SED_F: 46.0, DOA_Error: 19.5, DOA_recall:72.0, seld_score (early stopping score): 0.39, best_seld_score: 0.38, best_epoch : 32

Epoch [35/50], train loss : 0.0070
Epoch [35/50], val loss : 0.0122
Epoch    35: reducing learning rate of group 0 to 3.2000e-07.
epoch_cnt: 34, time: 114.81s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.61, SED_F: 46.6, DOA_Error: 19.5, DOA_recall:72.1, seld_score (early stopping score): 0.38, best_seld_score: 0.38, best_epoch : 32

Epoch [36/50], train loss : 0.0070
Epoch [36/50], val loss : 0.0122
epoch_cnt: 35, time: 114.38s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.61, SED_F: 46.5, DOA_Error: 19.5, DOA_recall:72.4, seld_score (early stopping score): 0.38, best_seld_score: 0.38, best_epoch : 32

Epoch [37/50], train loss : 0.0070
Epoch [37/50], val loss : 0.0122
epoch_cnt: 36, time: 114.40s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.62, SED_F: 46.3, DOA_Error: 19.5, DOA_recall:72.1, seld_score (early stopping score): 0.38, best_seld_score: 0.38, best_epoch : 32

Epoch [38/50], train loss : 0.0070
Epoch [38/50], val loss : 0.0122
Epoch    38: reducing learning rate of group 0 to 6.4000e-08.
epoch_cnt: 37, time: 114.40s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.61, SED_F: 46.4, DOA_Error: 19.5, DOA_recall:72.2, seld_score (early stopping score): 0.38, best_seld_score: 0.38, best_epoch : 32

Epoch [39/50], train loss : 0.0070
Epoch [39/50], val loss : 0.0122
epoch_cnt: 38, time: 114.42s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.62, SED_F: 46.0, DOA_Error: 19.5, DOA_recall:71.9, seld_score (early stopping score): 0.39, best_seld_score: 0.38, best_epoch : 32

Epoch [40/50], train loss : 0.0070
Epoch [40/50], val loss : 0.0124
epoch_cnt: 39, time: 114.42s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.62, SED_F: 45.8, DOA_Error: 19.5, DOA_recall:71.7, seld_score (early stopping score): 0.39, best_seld_score: 0.38, best_epoch : 32

Epoch [41/50], train loss : 0.0070
Epoch [41/50], val loss : 0.0121
Epoch    41: reducing learning rate of group 0 to 1.2800e-08.
epoch_cnt: 40, time: 114.37s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.61, SED_F: 46.3, DOA_Error: 19.6, DOA_recall:72.4, seld_score (early stopping score): 0.38, best_seld_score: 0.38, best_epoch : 32
/home/huangd5/.local/lib/python3.8/site-packages/torchaudio/backend/utils.py:46: UserWarning: "torchaudio.USE_SOUNDFILE_LEGACY_INTERFACE" flag is deprecated and will be removed in 0.9.0. Please remove the use of flag.
  warnings.warn(

Epoch [42/50], train loss : 0.0070
Epoch [42/50], val loss : 0.0121
epoch_cnt: 41, time: 114.44s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.61, SED_F: 46.5, DOA_Error: 19.4, DOA_recall:72.2, seld_score (early stopping score): 0.38, best_seld_score: 0.38, best_epoch : 32

Epoch [43/50], train loss : 0.0070
Epoch [43/50], val loss : 0.0122
epoch_cnt: 42, time: 114.40s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.62, SED_F: 45.7, DOA_Error: 19.8, DOA_recall:72.0, seld_score (early stopping score): 0.39, best_seld_score: 0.38, best_epoch : 32

Epoch [44/50], train loss : 0.0070
Epoch [44/50], val loss : 0.0123
Epoch    44: reducing learning rate of group 0 to 2.5600e-09.
epoch_cnt: 43, time: 114.34s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.62, SED_F: 46.2, DOA_Error: 19.6, DOA_recall:72.1, seld_score (early stopping score): 0.39, best_seld_score: 0.38, best_epoch : 32

Epoch [45/50], train loss : 0.0070
Epoch [45/50], val loss : 0.0123
epoch_cnt: 44, time: 114.24s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.61, SED_F: 46.3, DOA_Error: 19.5, DOA_recall:72.2, seld_score (early stopping score): 0.38, best_seld_score: 0.38, best_epoch : 32

Epoch [46/50], train loss : 0.0070
Epoch [46/50], val loss : 0.0122
epoch_cnt: 45, time: 114.31s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.62, SED_F: 46.4, DOA_Error: 19.5, DOA_recall:72.1, seld_score (early stopping score): 0.38, best_seld_score: 0.38, best_epoch : 32

Epoch [47/50], train loss : 0.0070
Epoch [47/50], val loss : 0.0122
epoch_cnt: 46, time: 114.33s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.62, SED_F: 46.0, DOA_Error: 19.5, DOA_recall:72.0, seld_score (early stopping score): 0.39, best_seld_score: 0.38, best_epoch : 32

Epoch [48/50], train loss : 0.0070
Epoch [48/50], val loss : 0.0121
epoch_cnt: 47, time: 114.28s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.61, SED_F: 46.9, DOA_Error: 19.4, DOA_recall:72.3, seld_score (early stopping score): 0.38, best_seld_score: 0.38, best_epoch : 47

Epoch [49/50], train loss : 0.0070
Epoch [49/50], val loss : 0.0121
epoch_cnt: 48, time: 114.35s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.61, SED_F: 46.5, DOA_Error: 19.3, DOA_recall:72.1, seld_score (early stopping score): 0.38, best_seld_score: 0.38, best_epoch : 47

Epoch [50/50], train loss : 0.0070
Epoch [50/50], val loss : 0.0122
epoch_cnt: 49, time: 114.37s, tr_loss: 0.01, 
		 DCASE2020 SCORES: SED_Error: 0.62, SED_F: 46.4, DOA_Error: 19.5, DOA_recall:71.8, seld_score (early stopping score): 0.39, best_seld_score: 0.38, best_epoch : 47


Results on validation split:
	Saved model for the best_epoch: 47
	SELD_score (early stopping score) : 0.38139241005606045

	DCASE2021 scores
	Class-aware localization scores: DOA_error: 19.4, F-score: 72.3
	Location-aware detection scores: Error rate: 0.61, F-score: 46.9
